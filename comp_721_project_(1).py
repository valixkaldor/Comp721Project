# -*- coding: utf-8 -*-
"""Comp_721_Project_(1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OW36Zhi23WGkfPockzPCifibDyVBsTFR

#Players
"""

import pandas as pd
import os
from pathlib import Path
df = pd.DataFrame()

import base64
import requests

master = "https://raw.githubusercontent.com/valixkaldor/Comp721Project/main/player_regular_season_career.txt"
req = requests.get(master)
req = req.text

df= pd.read_csv(master)
df

"""#Ensamble Univariate Player Detection

"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
lst = [['gp','minutes'],['pts','dreb'],['oreb','reb'],['asts','stl'],['blk','turnover'],['pf','fga'],['fgm','fta'],['ftm','tpm']]
for i in lst:
  df[i[0]]=df[i[0]].astype(int)
  df[i[1]]=df[i[1]].astype(int)
  plt.figure(figsize=(16,6))
  plt.subplot(1,2,1)
  sns.distplot(df[i[0]])
  plt.subplot(1,2,2)
  sns.distplot(df[i[1]])

"""#**Ensamble Univariate Player Outlier Detection**"""

highest =[]
lowest =[]
Metrics = ['gp','minutes','pts','dreb','oreb','reb','asts','stl','blk','turnover','pf','fga','fgm','fta','ftm','tpm']
for i in Metrics:
  highest.append(df[i].mean() + 3*df[i].std())
  lowest.append(df[i].mean() - 1*df[i].std())

#gp = df[(df['gp'] > highest[1])]
gp = []
minutes=[]
pts=[]
dreb=[]
oreb=[]
reb=[]
asts=[]
stl=[]
blk=[]
turnover=[]
pf=[]
fga=[]
fgm=[]
fta=[]
ftm=[]
tpm=[]

NoMetrics = len(Metrics)
OutstandingPlayers=[gp,minutes,pts,dreb,oreb,reb,asts,stl,blk,turnover,pf,fga,fgm,fta,ftm,tpm]
for i in range(NoMetrics):
  OutstandingPlayers[i].append(df[(df[Metrics[i]] > highest[i])])
  #OutstandingPlayers[i].append(df[(df[Metrics[i]] < lowest[i])])

Players = df['ilkid']#.values.tolist()
score=[]
for i in range(len(Players)):
  score.append(0)

Players = df['ilkid'].values.tolist(),score,df['firstname'],df['lastname']

def adder(mylist):
  for i in mylist[0]['ilkid']:
    for ic in range(len(Players[0])):
      if i== Players[0][ic]:
        Players[1][ic]=Players[1][ic]+1

adder(gp)
adder(minutes)
adder(pts)
adder(dreb)
adder(oreb)
adder(reb)
adder(asts)
adder(stl)
adder(blk)
adder(turnover)
adder(pf)
adder(fga)
adder(fta)
adder(ftm)
adder(tpm)

for i in range(len(Players[0])):
  if Players[1][i]>8:
    print(Players[0][i],' ',Players[2][i],' ',Players[3][i])

"""#**MultiVariate Outlier Detection**"""

df1=df

df=df1

df = df[['gp','minutes','pts','dreb','oreb','reb','asts','stl','blk','turnover','pf','fga','fgm','fta','ftm','tpm']]
df = df.dropna()
df = df.to_numpy()
df

# Covariance matrix
covariance  = np.cov(df , rowvar=False)

# Covariance matrix power of -1
covariance_pm1 = np.linalg.matrix_power(covariance, -1)

# Center point
centerpoint = np.mean(df , axis=0)

import pandas as pd
import numpy as np
from scipy.stats import chi2
from matplotlib import patches
import matplotlib.pyplot as plt
distances = []
for i, val in enumerate(df):
      p1 = val
      p2 = centerpoint
      distance = (p1-p2).T.dot(covariance_pm1).dot(p1-p2)
      distances.append(distance)
distances = np.array(distances)

# Cutoff (threshold) value from Chi-Sqaure Distribution for detecting outliers
print(df.shape[1])
cutoff = chi2.ppf(0.999999999, df.shape[1])
cutoff = cutoff*3
print(cutoff)
# Index of outliers
outlierIndexes = np.where(distances > cutoff)


#print('--- Index of Outliers ----')
#print(outlierIndexes)

#print('--- Observations found as outlier -----')
#print(df[ distances > cutoff , :])

myout = np.where(distances > np.mean(distances)+3*np.std(distances))
intd = myout[0].tolist()

df4=df1
df4=df4.values.tolist()
for i in intd:
  print(df4[i][0],' ',df4[i][1],' ',df4[i][2])

ind = outlierIndexes[0].tolist()
print(len(ind))
df4=df1
df4=df4.values.tolist()
for i in ind:
  print(df4[i][0],' ',df4[i][1],' ',df4[i][2])

pearson = covariance[0, 1]/np.sqrt(covariance[0, 0] * covariance[1, 1])
ell_radius_x = np.sqrt(1 + pearson)
ell_radius_y = np.sqrt(1 - pearson)
lambda_, v = np.linalg.eig(covariance)
lambda_ = np.sqrt(lambda_)

# Ellipse patch
ellipse = patches.Ellipse(xy=(centerpoint[0], centerpoint[1]),
                  width=lambda_[0]*np.sqrt(cutoff)*2, height=lambda_[1]*np.sqrt(cutoff)*2,
                  angle=np.rad2deg(np.arccos(v[0, 0])), edgecolor='#fab1a0')
ellipse.set_facecolor('#0984e3')
ellipse.set_alpha(0.5)
fig = plt.figure()
ax = plt.subplot()
ax.add_artist(ellipse)
plt.scatter(df[: , 0], df[ : , 1])
plt.show()

"""#Teams

"""

import numpy as np
import pandas as pd

from sklearn import svm
from sklearn.model_selection import cross_validate
from sklearn.preprocessing import MinMaxScaler

from sklearn import datasets
from sklearn import preprocessing

import pandas as pd

import dask.dataframe as dd
np.random.seed(42)

import pandas as pd
import os
from pathlib import Path
df = pd.DataFrame()

import base64
import requests

master = "https://raw.githubusercontent.com/valixkaldor/Comp721Project/main/teams.txt"
req = requests.get(master)
req = req.text
teamsdf = pd.read_csv(master)

teamsdf

#Getting dictionary of all team tags

teamslist = []

for j,rows in teamsdf.iterrows():
    teamslist.append(rows['team'])

print(teamslist)

# WIN/LOSS RATIO
# Were first going to look at the #wins vs #losses for the past season

df = pd.read_csv("https://raw.githubusercontent.com/valixkaldor/Comp721Project/main/team_season.txt")
df.head()

#filtering only from the previous year

rslt_df = df.loc[df['year'] > 2002]
rslt_df.head()

#calculating win/loss for each team

dic = {}

for i in teamslist:
    dic[i] = [0.0,0.0]

for j,rows in rslt_df.iterrows():
    if rows['team'] not in dic.keys():
        dic[rows['team']] = [int(rows['won']), int(rows['lost'])]
    else:
        dic[rows['team']][0] += int(rows['won'])
        dic[rows['team']][1] += int(rows['lost'])

w_l_dict = {}

for i in dic.keys():
    w_l_dict[i] = dic[i][0]/(dic[i][1]+1)

w_l_list = sorted(w_l_dict.items(),key=lambda x:x[1])
print(w_l_list)
sortdict = dict(w_l_list)
print(sortdict)

# coach career-wide win/loss

dfcoach = pd.read_csv("https://raw.githubusercontent.com/valixkaldor/Comp721Project/main/coaches_season.txt")
dfcoach.head()

#current (2004-05) coaches in NBA

curr_coaches = dfcoach
curr_coaches.head()

# dictionaary of clubs with the value being the current coach

coach_dic = {}
for j,rows in curr_coaches.iterrows():
    coach_dic[rows['team']] = rows['coachid']

print(coach_dic)

#load in coach history

dfcoach_history = pd.read_csv("https://raw.githubusercontent.com/valixkaldor/Comp721Project/main/coaches_career.txt")
dfcoach_history.head()

# calculate career win/loss for each coach

careerdic = {}
for j,rows in dfcoach_history.iterrows():
    careerdic[rows['coachid']] = (float(rows['season_win'])+float(rows['playoff_win']))/(float(rows['season_loss'])+float(rows['playoff_loss'])+1)

print(careerdic)

# associate each team with it's current coaches w/l ratio

coach_ranking = {}
for i in coach_dic.keys():
    if coach_dic[i] in careerdic:
        coach_ranking[i] = careerdic[coach_dic[i]]
    else:
        coach_ranking[i] = 0.0

print(coach_ranking)

#avg player rating
#load in player statistics

dfplayer = pd.read_csv("https://raw.githubusercontent.com/valixkaldor/Comp721Project/main/player_regular_season.txt")
dfplayer.head()

#load in 2004-05 nba players

curr_players = dfplayer.loc[dfplayer['year'] == 2004]
curr_players.head()

#associate each team with a list of its players

playerdic = {}

for i in sortdict.keys():
    playerdic[i] = []

for j,rows in curr_players.iterrows():
    if rows['team'] != 'TOT':
        playerdic[rows['team']].append(rows['ilkid'])

print(playerdic)

#load in player career statistics

dfplayer_history = pd.read_csv("https://raw.githubusercontent.com/valixkaldor/Comp721Project/main/player_regular_season.txt")
dfplayer_history.head()

# take their form in the last 3 years

playerform = dfplayer_history.loc[dfplayer['year'] > 2000]
playerform.head()

#aggregate their statistics
#pts, turnovers, and rebounds are the most important statistics in basketball
#number of minutes also recorded to measure their efficiency

aggregations = {
    'pts':'sum',
    'turnover':'sum',
    'reb':'sum',
    'minutes':'sum',
}

df_player_stats = playerform.groupby('ilkid',as_index=False).agg(aggregations)

df_player_stats.head()

#create a dictionary of each current player with their statistics

dict_player_stats = {}

for j,rows in df_player_stats.iterrows():
    dict_player_stats[rows['ilkid']] = [0,0,0,1]

for j,rows in df_player_stats.iterrows():
    dict_player_stats[rows['ilkid']] = [0,0,0,1]


for j,rows in df_player_stats.iterrows():
    dict_player_stats[rows['ilkid']] = [float(rows['pts'])
                                        , float(rows['turnover'])
                                        , float(rows['reb'])
                                        , float(rows['minutes'])]

print(dict_player_stats)

#calculate avg pts/min, turnovers/min, rebounds/min for normalization

total_pts = 0
total_tnv = 0
total_rbs = 0
total_mins = 0

for i in dict_player_stats.keys():
    total_pts+=dict_player_stats[i][0]
    total_tnv+=dict_player_stats[i][1]
    total_rbs+=dict_player_stats[i][2]
    total_mins+=dict_player_stats[i][3]

print(total_pts,total_tnv,total_rbs,total_mins)

avgs = [total_pts/total_mins,total_tnv/total_mins,total_rbs/total_mins]
print(avgs)

#normalize and aggregate statistics to get an avg rating for each player

dict_avg_stats = {}

for i in dict_player_stats.keys():
    dict_avg_stats[i] = np.max([(dict_player_stats[i][0]/(dict_player_stats[i][3]+1))/avgs[0]
    ,(dict_player_stats[i][1]/(dict_player_stats[i][3]+1))/avgs[1],(dict_player_stats[i][2]/(dict_player_stats[i][3]+1))/avgs[2]])

print(dict_avg_stats)

sorted_list = sorted(dict_avg_stats.items(),key=lambda x:x[1])
sortplayers = dict(sorted_list)
print(sortplayers)

print(sortplayers['JORDAMI01'])

#for each team avg the scores of their top ten players

team_player_rating_dict = {}

for i in playerdic.keys():
    list = []
    for j in playerdic[i]:
        list.append(sortplayers[j])

    print(list)

    if len(list) >0:
        team_player_rating_dict[i] = np.mean(sorted(list)[:12])

print(team_player_rating_dict)

#associate each current team with its w/l ratio, coach score, player score

teams0405dic = {}

for i in playerdic:
    if len(playerdic[i])>0:
        if i in coach_ranking:
            teams0405dic[i] = [sortdict[i],coach_ranking[i],team_player_rating_dict[i]]
        else:
            teams0405dic[i] = [sortdict[i],0.5,team_player_rating_dict[i]]

print(teams0405dic)

for i in teams0405dic:
  print(i,teams0405dic[i])

#normalize scores and aggregate them
#

normalized_teams_dic = {}

wl = []
coach_rat = []
player_rat = []

for i in teams0405dic:
    wl.append(teams0405dic[i][0])
    coach_rat.append(teams0405dic[i][1])
    player_rat.append(teams0405dic[i][2])

feature_avgs = [np.mean(wl),np.mean(coach_rat),np.mean(player_rat)]

#modify to adjust how rating is aggregated between the three scores
#to use all three, use
#normalized_teams_dic[i] = np.mean([teams0405dic[i][0]/feature_avgs[0],teams0405dic[i][1]/feature_avgs[1],teams0405dic[i][2]/feature_avgs[2]])


for i in teams0405dic:
    normalized_teams_dic[i] = np.mean([teams0405dic[i][0]/feature_avgs[0],
                                       #teams0405dic[i][1]/feature_avgs[1],
                                       #teams0405dic[i][2]/feature_avgs[2]
                                       ])



sorted_final = sorted(normalized_teams_dic.items(),key=lambda x:x[1])
sorted_final_list = dict(sorted_final)
print(sorted_final_list)

df_0405data = pd.read_csv("https://raw.githubusercontent.com/valixkaldor/Comp721Project/main/games.csv")
df_0405data = df_0405data.loc[df_0405data['SEASON'] == 2004]

df_0405data

#translate team ids of testing set to training set

teamid_dict = {
    "1610612737":"ATL",
    "1610612738":"BOS",
    "1610612740":"NOH",
    "1610612741":"CHI",
    "1610612742":"DAL",
    "1610612743":"DEN",
    "1610612744":"BOS",
    "1610612745":"HOU",
    "1610612746":"LAC",
    "1610612747":"LAL",
    "1610612748":"MIA",
    "1610612749":"MIL",
    "1610612750":"MIN",
    "1610612751":"NJN",
    "1610612752":"NYK",
    "1610612738":"BOS",
    "1610612753":"ORL",
    "1610612754":"IND",
    "1610612755":"PHI",
    "1610612756":"PHO",
    "1610612757":"POR",
    "1610612758":"SAC",
    "1610612759":"SAS",
    "1610612760":"SEA",
    "1610612761":"TOR",
    "1610612762":"UTA",
    "1610612763":"MEM",
    "1610612764":"WAS",
    "1610612765":"DET",
    "1610612766":"CHR",
    "1610612739":"CLE",
    "1610612744":"GSW",
}

features = {"HOME_TEAM_ID","VISITOR_TEAM_ID","HOME_TEAM_WINS"}
testdf = df_0405data[features]
testdf.head()

#replace home team id with our abbreviations

count = 0
for i,rows in testdf.iterrows():
    testdf.at[i,'HOME_TEAM_ID'] = teamid_dict[str(rows["HOME_TEAM_ID"])]
    count+=1

testdf.head()

#replace away team id with our abbreviations


count = 0
for i,rows in testdf.iterrows():
    testdf.at[i,'VISITOR_TEAM_ID'] = teamid_dict[str(rows["VISITOR_TEAM_ID"])]
    count+=1
testdf = testdf.reset_index()
testdf.head()

testdf

#prediction via just taking higher score

def predict_simple(team_1,team_2):
    if sorted_final_list[team_1] >= sorted_final_list[team_2]:
        return 1
    else:
        return 0

#prediction by calculating a probability and using that prob as a distribution
#to randomly pick a result

import random

def predict_sample(team1,team2):
    prob_dist = [sorted_final_list[team1]**4/(sorted_final_list[team1]**4+sorted_final_list[team2]**4),
                 sorted_final_list[team2]**4/(sorted_final_list[team1]**4+sorted_final_list[team2]**4)]
    outcomes = [1,0]
    return random.choices(outcomes,prob_dist)

#evaluate accuracy

def evaluate_simple(X,y):
    num_correct = 0

    num_matches = len(X.index)

    for i,rows in X.iterrows():
        prediction = predict_simple(X.at[i,'HOME_TEAM_ID'],X.at[i,'VISITOR_TEAM_ID'])
        if prediction == y[i]:
            num_correct+=1

    return num_correct/float(num_matches)

#evaluate accuracy

def evaluate_sample(X,y):
    num_correct = 0

    num_matches = len(X.index)

    for i,rows in X.iterrows():
        prediction = predict_sample(X.at[i,'HOME_TEAM_ID'],X.at[i,'VISITOR_TEAM_ID'])
        if prediction == y[i]:
            num_correct+=1

    return num_correct/float(num_matches)

x = testdf.drop(['HOME_TEAM_WINS'], axis = 1)
y = testdf.loc[:,'HOME_TEAM_WINS'].values

x.head()

y

evaluate_simple(x,y)

evaluate_sample(x,y)